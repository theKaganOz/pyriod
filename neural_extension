import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from deap import base, creator, tools, algorithms
import random


def create_neural_network(input_dim, layers_config, activation='relu', dropout_rate=0.0, learning_rate=0.001):
    """
    Dynamically creates a neural network model.
    """
    model = Sequential()
    for i, units in enumerate(layers_config):
        if i == 0:
            model.add(Dense(units, activation=activation, input_dim=input_dim))
        else:
            model.add(Dense(units, activation=activation))
        if dropout_rate > 0:
            model.add(Dropout(dropout_rate))

    model.add(Dense(1))  # Output layer
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    return model


def optimize_neural_network(X, y, n_generations=10, population_size=10, input_dim=None):
    """
    Uses NSGA-II to optimize the neural network architecture.
    """
    input_dim = input_dim or X.shape[1]

    def evaluate(individual):
        layers = [int(neurons) for neurons in individual if neurons > 0]
        if len(layers) == 0:
            return 1e6, 1e6

        model = create_neural_network(input_dim, layers)
        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)
        model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)
        pred = model.predict(X_val).flatten()
        mse = mean_squared_error(y_val, pred)
        n_params = model.count_params()
        return mse, n_params

    creator.create("FitnessMulti", base.Fitness, weights=(-1.0, -1.0))
    creator.create("Individual", list, fitness=creator.FitnessMulti)

    toolbox = base.Toolbox()
    toolbox.register("attr_int", random.randint, 0, 128)
    toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_int, n=5)
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)
    toolbox.register("evaluate", evaluate)
    toolbox.register("mate", tools.cxTwoPoint)
    toolbox.register("mutate", tools.mutGaussian, mu=64, sigma=32, indpb=0.5)
    toolbox.register("select", tools.selNSGA2)

    pop = toolbox.population(n=population_size)
    stats = tools.Statistics(lambda ind: ind.fitness.values)
    stats.register("avg", np.mean, axis=0)
    stats.register("min", np.min, axis=0)

    algorithms.eaMuPlusLambda(pop, toolbox, mu=population_size, lambda_=population_size, cxpb=0.5, mutpb=0.3,
                               ngen=n_generations, stats=stats, verbose=True)

    best = tools.selBest(pop, 1)[0]
    return best, stats


def forecast_residuals_with_nn(residual_series, forecast_horizon=10, lag=10, n_generations=5, pop_size=5):
    """
    Forecasts residual series using optimized neural network architecture.

    Parameters:
    - residual_series (array-like): Time series residuals
    - forecast_horizon (int): Number of future steps to forecast
    - lag (int): Number of past lags to use as input features
    - n_generations (int): Optimization steps
    - pop_size (int): Population size for NSGA-II

    Returns:
    - forecasts (list): Forecasted future values
    - model (Keras model): Trained neural model
    """
    # Supervised learning dataset creation
    X, y = [], []
    for i in range(lag, len(residual_series)):
        X.append(residual_series[i-lag:i])
        y.append(residual_series[i])

    X = np.array(X)
    y = np.array(y)

    # Optimize architecture
    best_architecture, _ = optimize_neural_network(X, y, n_generations=n_generations, population_size=pop_size)
    layers = [int(n) for n in best_architecture if n > 0]
    model = create_neural_network(X.shape[1], layers)
    model.fit(X, y, epochs=50, batch_size=32, verbose=0)

    # Forecasting
    input_seq = list(residual_series[-lag:])
    forecasts = []
    for _ in range(forecast_horizon):
        pred = model.predict(np.array(input_seq[-lag:]).reshape(1, -1), verbose=0)[0][0]
        forecasts.append(pred)
        input_seq.append(pred)

    return forecasts, model
